{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a87b03f2-e248-4ffc-92b5-8f0005003a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 344 ms (started: 2022-06-11 08:03:27 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random, math, os\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append(\"../utils/\")\n",
    "from recsys_metric import mrr\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a04f5fcb-e0aa-42b1-ba14-96b3e9e86c40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 745 µs (started: 2022-06-11 08:03:28 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def get_data(train_file_path, val_file_path, overview=False, concat_val=False):\n",
    "    # 读取数据\n",
    "    \n",
    "    trn_raw_data = pd.read_csv(train_file_path, sep=',', engine='python')\n",
    "    val_raw_data = pd.read_csv(val_file_path, sep=',', engine='python')\n",
    "    if concat_val:\n",
    "        trn_raw_data = pd.concat([trn_raw_data, val_raw_data])\n",
    "    \n",
    "    # 分割训练和验证集\n",
    "    \n",
    "    trn_data = trn_raw_data.groupby('session_id')['item_id'].apply(list).reset_index()\n",
    "    val_data = val_raw_data.groupby('session_id')['item_id'].apply(list).reset_index()\n",
    "\n",
    "    trn_user_items = {}\n",
    "    val_user_items = {}\n",
    "    \n",
    "    # 将数组构造成字典的形式{session_id: [item_id1, item_id2,...,item_idn]}\n",
    "    for session, item in zip(*(list(trn_data['session_id']), list(trn_data['item_id']))):\n",
    "        trn_user_items[session] = set(item)\n",
    "\n",
    "    for session, item in zip(*(list(val_data['session_id']), list(val_data['item_id']))):\n",
    "        val_user_items[session] = set(item)\n",
    "    \n",
    "    if overview:\n",
    "        print(f'trn_raw_data:\\n {trn_raw_data} \\n val_raw_data:\\n {val_raw_data}')\n",
    "        print('trn_data:\\n',trn_data)\n",
    "        print('val_data:\\n', val_data)\n",
    "    \n",
    "    return trn_user_items, val_user_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a081dfb6-30b1-4ad7-a055-2b13301cb939",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.2 ms (started: 2022-06-11 08:03:28 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def Item_CF(trn_user_items, val_user_items, K, N, candidate_items=None, overview=False, prediction=False):\n",
    "    '''\n",
    "    trn_user_items: 表示训练数据，格式为：{user_id1: [item_id1, item_id2,...,item_idn], user_id2...}\n",
    "    val_user_items: 表示验证数据，格式为：{user_id1: [item_id1, item_id2,...,item_idn], user_id2...}\n",
    "    K: Ｋ表示的是相似商品的数量，为每个用户交互的每个商品都选择其最相似的K个商品\n",
    "    N: N表示的是给用户推荐的商品数量，给每个用户推荐相似度最大的N个商品\n",
    "    '''\n",
    "\n",
    "    # 建立user->item的倒排表\n",
    "    # 倒排表的格式为: {user_id1: [item_id1, item_id2,...,item_idn], user_id2: ...} 也就是每个用户交互过的所有商品集合\n",
    "    # 由于输入的训练数据trn_user_items,本身就是这中格式的，所以这里不需要进行额外的计算\n",
    "    \n",
    "\n",
    "    # 计算商品协同过滤矩阵\n",
    "    # 即利用user-items倒排表统计商品与商品之间被共同的用户交互的次数\n",
    "    # 商品协同过滤矩阵的表示形式为：sim = {item_id1: {item_id２: num1, item_id3: num3,...}, item_id３: {item_id４: num２,...}, ...}\n",
    "    # 商品协同过滤矩阵是一个双层的字典，用来表示商品之间共同交互的用户数量\n",
    "    # 在计算商品协同过滤矩阵的同时还需要记录每个商品被多少不同用户交互的次数，其表示形式为: num = {item_id1：num1, item_id２:num2, ...}\n",
    "    sim = {}#两个物品同时被某些用户喜欢的总次数(不止一个用户)\n",
    "    num = {}#每个物品的总共的 被喜欢(交互)数\n",
    "    print('构建相似性矩阵．．．')\n",
    "    #遍历每一个user交互过的items列表，统计两个不同的item共同被user(不止一个，而是trn_user_items中的所有user)交互的总次数\n",
    "    for uid, items in tqdm(trn_user_items.items()):\n",
    "        #对于当前items列表中的每一个item\n",
    "        for i in items:\n",
    "            #统计item i 被用户交互的总次数\n",
    "            if i not in num:\n",
    "                num[i] = 0\n",
    "            num[i] += 1\n",
    "            #统计 item i 和 item j 被共同交互的总次数\n",
    "            if i not in sim:\n",
    "                sim[i] = {}\n",
    "            for j in items:\n",
    "                if j not in sim[i]:\n",
    "                    sim[i][j] = 0\n",
    "                if i != j:\n",
    "                    sim[i][j] += 1/math.log1p(len(items) * 1.)\n",
    "    \n",
    "    # 计算物品的相似度矩阵\n",
    "    # 商品协同过滤矩阵其实相当于是余弦相似度的分子部分,还需要除以分母,即两个商品被交互的用户数量的乘积\n",
    "    # 两个商品被交互的用户数量就是上面统计的num字典\n",
    "    print('计算协同过滤矩阵．．．')\n",
    "    for i, items in tqdm(sim.items()):\n",
    "        for j, score in items.items():\n",
    "            if i != j:\n",
    "                sim[i][j] = score / math.sqrt(num[i] * num[j])\n",
    "    \n",
    "    for i, relations in sim.items():\n",
    "        if relations:\n",
    "            max_num = relations[max(relations, key=relations.get)]\n",
    "            if max_num!=0:\n",
    "                # 对字典进行归一化操作之后返回新的字典\n",
    "                sim[i] = {k: v / max_num for k, v in relations.items()}\n",
    "                \n",
    "        \n",
    "    # 对验证数据中的每个用户进行TopN推荐\n",
    "    # 在对用户进行推荐之前需要先通过商品相似度矩阵得到 与 当前测试用户交互过的商品最相似的前K个商品，\n",
    "    # 然后对这K个用户交互的商品中除当前测试用户训练集中交互过的商品以外的商品计算最终的相似度分数\n",
    "    # 最终推荐的候选商品的相似度分数是由多个相似商品对该商品分数的一个累加和\n",
    "    items_rank = {}\n",
    "    print('给用户进行推荐．．．')\n",
    "    for uid, _ in tqdm(val_user_items.items()):\n",
    "        items_rank[uid] = {} # 存储用户候选的推荐商品\n",
    "        for hist_item in trn_user_items[uid]: # 遍历该用户历史喜欢的商品，用来下面寻找其相似的商品\n",
    "            # 回顾：sim = {item_id1: {item_id２: num1, item_id3: num3,...}, item_id３: {item_id４: num２,...}, ...}\n",
    "            # 回顾：trn_user_items = {user_id1: [item_id1, item_id2,...,item_idn], user_id2: ...} \n",
    "            #print(sim[hist_item])# {item_id２: num1, item_id3: num3,...}\n",
    "            for item, score in sorted(sim[hist_item].items(), key=lambda x: x[1], reverse=True)[:K]:\n",
    "                if item not in trn_user_items[uid]: # 进行推荐的商品一定不能在历史喜欢商品中出现\n",
    "                    #计算当前uid对当前item的打分\n",
    "                    if item not in items_rank[uid]:\n",
    "                        items_rank[uid][item] = 0\n",
    "                    items_rank[uid][item] += score\n",
    "                    \n",
    "    \n",
    "    print('为每个用户筛选出相似度分数最高的Ｎ个商品...')\n",
    "    if not prediction:\n",
    "        #print(items_rank)#{user1:{item1:score1,item2:score2,...},user2:{item6:score6,item9:score9,...}}\n",
    "        items_rank = {k: sorted(v.items(), key=lambda x: x[1], reverse=True)[:N] for k, v in items_rank.items()}\n",
    "        items_rank = {k: [x[0] for x in v] for k, v in items_rank.items()}\n",
    "    else:\n",
    "        items_rank = {k: sorted(v.items(), key=lambda x: x[1], reverse=True) for k, v in items_rank.items()}\n",
    "        items_rank = {k: [x[0] for x in v if x[0] in candidate_items][:N] for k, v in items_rank.items()}\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    if overview:\n",
    "        #查看一下sim   \n",
    "        for k ,v in sim.items():\n",
    "            print(f\"similarity[{k}]:\") \n",
    "            print(v)\n",
    "            break\n",
    "            \n",
    "    return items_rank, sim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e18ad0eb-dad8-4e73-ae3c-393df18736a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 603 µs (started: 2022-06-11 08:03:29 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def rank_itemcf(target_dict, overview=False):\n",
    "    item_id_rank_arr = pd.DataFrame.from_dict(target_dict, orient='index').reset_index().rename(columns={'index': 'session_id'}).fillna(-1).astype(int)\n",
    "    lack_col_num = 101 - len(item_id_rank_arr.columns)\n",
    "    for i in range(100-lack_col_num,100):\n",
    "        item_id_rank_arr[i]=-1\n",
    "     \n",
    "    if overview:\n",
    "        print(f\"lack_col_num:{lack_col_num}\")\n",
    "        display(item_id_rank_arr)\n",
    "    \n",
    "    res_df = pd.melt(item_id_rank_arr, id_vars=['session_id'], value_vars=range(100)).sort_values(['session_id','variable']).rename(columns={'value': 'item_id'}).drop(['variable'], axis=1)\n",
    "    res_df[\"rank\"] = (list(range(1,101))*len(target_dict))\n",
    "    \n",
    "    \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7856b7-98e6-4a0f-b799-744fc5f5fd41",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac0594e3-4ac3-46ce-8925-fa754ee94ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_user_items len:1000000,val_user_items len:81618\n",
      "time: 25.4 s (started: 2022-06-11 08:03:34 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "train_file_path = '../../recsys2022/train_sessions.csv'\n",
    "val_file_path = '../datasets/train_last_1m.csv'\n",
    "trn_user_items, val_user_items = get_data(train_file_path, val_file_path, concat_val=False)\n",
    "print(f'trn_user_items len:{len(trn_user_items)},val_user_items len:{len(val_user_items)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b8a8dac-b6c1-4fea-975b-7e3c3955d62e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "构建相似性矩阵．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1000000/1000000 [00:23<00:00, 43135.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算协同过滤矩阵．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 23496/23496 [00:06<00:00, 3543.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给用户进行推荐．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 81618/81618 [03:38<00:00, 373.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为每个用户筛选出相似度分数最高的Ｎ个商品...\n",
      "构建相似性矩阵．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1000000/1000000 [00:23<00:00, 43259.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算协同过滤矩阵．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 23496/23496 [00:06<00:00, 3569.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给用户进行推荐．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 81618/81618 [03:46<00:00, 360.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为每个用户筛选出相似度分数最高的Ｎ个商品...\n",
      "构建相似性矩阵．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1000000/1000000 [00:23<00:00, 42834.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算协同过滤矩阵．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 23496/23496 [00:06<00:00, 3538.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给用户进行推荐．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 81618/81618 [04:16<00:00, 318.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为每个用户筛选出相似度分数最高的Ｎ个商品...\n",
      "构建相似性矩阵．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1000000/1000000 [00:23<00:00, 42905.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算协同过滤矩阵．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 23496/23496 [00:06<00:00, 3519.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给用户进行推荐．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 81618/81618 [04:31<00:00, 300.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为每个用户筛选出相似度分数最高的Ｎ个商品...\n",
      "构建相似性矩阵．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1000000/1000000 [00:23<00:00, 43016.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算协同过滤矩阵．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 23496/23496 [00:06<00:00, 3527.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给用户进行推荐．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 81618/81618 [05:31<00:00, 246.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为每个用户筛选出相似度分数最高的Ｎ个商品...\n",
      "{400: 0.16843929730413187, 500: 0.1686072146381592, 800: 0.16871724946498262, 1000: 0.16877922789723332, 2000: 0.16880877727791824}\n",
      "time: 27min 49s (started: 2022-06-11 09:22:48 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# 計算ItemCF\n",
    "k_list = [4000, 8000, 10000, 20000]\n",
    "mrr_k_records={}\n",
    "for k in k_list:\n",
    "    n=100\n",
    "    rec_items, sim = Item_CF(trn_user_items, val_user_items, k, n, prediction=False)\n",
    "\n",
    "\n",
    "    # rank item & output rank result\n",
    "    eva_res = rank_itemcf(rec_items)\n",
    "    eva_label = pd.read_csv('../datasets/purchases_last_1m.csv')\n",
    "\n",
    "    mrr_score = mrr(eva_res, eva_label, overview=False)\n",
    "    mrr_k_records[k] = mrr_score\n",
    "    # print(mrr_score)\n",
    "    # display(f\"eva_res shape:{eva_res.shape}\", eva_res.iloc[95:105,:])\n",
    "    \n",
    "print(mrr_k_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19e23a08-705a-43c7-94a1-26314a257131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.09500869597028379, 2: 0.1251135352303383, 3: 0.13965544101748156, 4: 0.14787793949921724, 5: 0.15199841935504121, 6: 0.15477301681355773, 10: 0.1599691541461026, 15: 0.16275048167764544, 30: 0.16575185779216386, 80: 0.16741300751998583}\n",
      "time: 307 µs (started: 2022-06-11 08:39:55 +00:00)\n"
     ]
    }
   ],
   "source": [
    "print(mrr_k_records)\n",
    "{1: 0.09500869597028379, 2: 0.1251135352303383, 3: 0.13965544101748156, \n",
    " 4: 0.14787793949921724, 5: 0.15199841935504121, 6: 0.15477301681355773, \n",
    " 10: 0.1599691541461026, 15: 0.16275048167764544, 30: 0.16575185779216386, \n",
    " 80: 0.16741300751998583, 100: 0.16779740173617033, 200: 0.16817674228462637, \n",
    " 300: 0.16833651410145736, 400: 0.16843929730413187, 500: 0.1686072146381592, \n",
    " 800: 0.16871724946498262, 1000: 0.16877922789723332, 2000: 0.16880877727791824}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f819a69-1ae2-4719-a132-55d2d72eaaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mrr_k_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693d6bc8-5f27-4e0e-a4a5-8c8100b08f3d",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68e5bd10-04ee-45da-8752-f08becef7dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_user_items len:1050000,val_user_items len:50000\n",
      "构建相似性矩阵．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1050000/1050000 [00:30<00:00, 34746.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算协同过滤矩阵．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 23683/23683 [00:07<00:00, 3084.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给用户进行推荐．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 50000/50000 [03:11<00:00, 261.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为每个用户筛选出相似度分数最高的Ｎ个商品...\n",
      "time: 1h 17min 49s (started: 2022-06-11 13:43:09 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "train_file_path = '../../recsys2022/train_sessions_purchases.csv'\n",
    "val_file_path = '../../recsys2022/test_leaderboard_sessions.csv'\n",
    "trn_user_items, val_user_items = get_data(train_file_path, val_file_path, concat_val=True)\n",
    "print(f'trn_user_items len:{len(trn_user_items)},val_user_items len:{len(val_user_items)}')\n",
    "\n",
    "\n",
    "# 計算ItemCF\n",
    "candidate_items = pd.read_csv('../../recsys2022/candidate_items.csv')['item_id'].tolist()\n",
    "k=2000 # 4 is also acceptable  \n",
    "n=100\n",
    "rec_items, sim = Item_CF(trn_user_items, val_user_items, k, n, candidate_items=candidate_items, prediction=True)\n",
    "\n",
    "\n",
    "# rank item & output rank result\n",
    "res = rank_itemcf(rec_items)\n",
    "res.to_csv(\"../datasets/results/leader_itemcf_k2000_train_purchases_test_candidate_filter_0611.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa39e87-e070-4485-aa3a-287a783d286c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# view_session_id = 113\n",
    "view_session_id = 659598\n",
    "print(rec_items[view_session_id])\n",
    "print(val_user_items[view_session_id])\n",
    "print(trn_user_items[view_session_id])\n",
    "print(sim[list(trn_user_items[view_session_id])[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76effb1e-5e46-459d-84d3-94835427be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4ce7ac-dd5d-41f3-a5e1-e2dee2e1b982",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sim.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b01b364-8ac7-4049-92c0-f476c0690537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print([len(sim[k]) for k in sim.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b95f4b-3b9b-426b-b0e7-473b48a9af61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = 115\n",
    "print(sim[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9524742-940e-436d-881c-2fd0ac4f961c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
